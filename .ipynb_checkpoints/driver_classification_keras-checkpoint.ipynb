{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statefarm Distracted Driver Classification (using Keras)\n",
    "## Satchel Grant\n",
    "\n",
    "The goal of this notebook is to classify the statefarm distracted drivers using Keras instead of TensorFlow. I also will implement a generator for data feeding to reduce the memory consumption.\n",
    "\n",
    "### Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "import scipy.misc as sci\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def show_img(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "\n",
    "First I read in the file paths of each of the image files and create a parallel array to store the labels and then I shuffle the order of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/WhiteElephant/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fb6e8e434206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexternal_drive_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Volumes/WhiteElephant/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhome_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexternal_drive_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/WhiteElephant/'"
     ]
    }
   ],
   "source": [
    "external_drive_path = '/Volumes/WhiteElephant/'\n",
    "home_path = os.getcwd()\n",
    "os.chdir(external_drive_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './statefarm_drivers/imgs/train'\n",
    "\n",
    "file_paths = []\n",
    "labels = []\n",
    "labels_to_nums = dict()\n",
    "for dir_name, subdir_list, file_list in os.walk(path):\n",
    "    if len(subdir_list) > 0:\n",
    "        label_types = subdir_list\n",
    "        for i,subdir in enumerate(subdir_list):\n",
    "            labels_to_nums[subdir] = i\n",
    "    for img_file in file_list:\n",
    "        if '.jpg' in img_file.lower():\n",
    "            file_paths.append(os.path.join(dir_name,img_file))\n",
    "            labels.append(labels_to_nums[dir_name[-2:]])\n",
    "\n",
    "n_labels = len(label_types)\n",
    "file_paths, labels = shuffle(file_paths, labels)\n",
    "print(\"Number of data samples: \" + str(len(file_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, n_classes):\n",
    "    one_hots = []\n",
    "    for label in labels:\n",
    "        one_hot = [0]*n_classes\n",
    "        one_hot[label] = 1\n",
    "        one_hots.append(one_hot)\n",
    "    return np.array(one_hots,dtype=np.float32)\n",
    "\n",
    "labels = one_hot_encode(labels,n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Next I create a generator to read in the images in batches. This reduces the amount of memory required to deal with the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7f3de263b355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msplit_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.75\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_valid_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_paths' is not defined"
     ]
    }
   ],
   "source": [
    "split_index = int(.75*len(file_paths))\n",
    "X_train_paths, y_train_paths = file_paths[:split_index], labels[:split_index]\n",
    "X_valid_paths, y_valid_paths = file_paths[split_index:], labels[split_index:]\n",
    "batch_size = 128\n",
    "train_steps_per_epoch = len(X_train_paths)//batch_size + 1\n",
    "if len(X_train_paths) % batch_size == 0: train_steps_per_epoch = len(X_train_paths)//batch_size\n",
    "\n",
    "\n",
    "def convert_images(paths, resize_dims):\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        img = mpimg.imread(path)\n",
    "        sized_img = sci.imresize(img, resize_dims)\n",
    "        images.append(sized_img)\n",
    "    return images\n",
    "\n",
    "def image_generator(file_paths, labels, batch_size, resize_dims=(120,120)):\n",
    "    while 1:\n",
    "        for batch in range(0, len(file_paths), batch_size):\n",
    "            images = convert_images(file_paths[batch:batch+batch_size])\n",
    "            batch_labels = labels[batch:batch+batch_size]\n",
    "            yield images, batch_labels\n",
    "\n",
    "\n",
    "train_generator = image_generator(X_train_paths, y_train_paths, batch_size)\n",
    "valid_generator = image_generator(X_valid_paths, y_valid_paths, len(X_valid_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, concatenate, \\\n",
    "        Flatten, Dropout, Lambda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "The model consists of 4 convolutional stacks followed by 2 dense layers. I had good success with this model while predicting the required steering angle from an image of a track for a car to drive around a track in real time. It is also a lightweight model making it quick and easy to train.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacks = []\n",
    "conv_shapes = [(1,1),(3,3),(5,5)]\n",
    "conv_depths = [8,10,10,10]\n",
    "pooling_filter = (2,2)\n",
    "pooling_stride = (2,2)\n",
    "dense_shapes = [150,50,n_labels]\n",
    "\n",
    "inputs = Input(shape=(resize_dims[0],resize_dims[1],3))\n",
    "inputs = BatchNormalization()(inputs)\n",
    "\n",
    "for shape in conv_shapes:\n",
    "    stacks.append(Conv2D(conv_depths[0], shape, padding='same', activation='elu')(inputs))\n",
    "layer = concatenate(stacks,axis=-1)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling2D(pooling_filter,strides=pooling_stride,padding='same')(layer)\n",
    "\n",
    "for i in range(1,len(conv_depths)):\n",
    "    stacks = []\n",
    "    for shape in conv_shapes:\n",
    "        stacks.append(Conv2D(conv_depths[i],shape,padding='same',activation='elu')(layer))\n",
    "    layer = concatenate(stacks,axis=-1)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling2D(pooling_filter,strides=pooling_stride, padding='same')(layer)\n",
    "\n",
    "layer = Flatten()(layer)\n",
    "layer = Dropout(0)(layer)\n",
    "\n",
    "for i in range(len(dense_shapes)-1):\n",
    "    layer = Dense(dense_shapes[i], activation='elu')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "\n",
    "outputs = Dense(dense_shapes[-1], activation='softmax')(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation\n",
    "The next cell trains the model using the adam optimizer and categorical_crossentropy. The adam optimizer is most efficient because it has specific learning rates for each parameter in the net and it uses momentum. Both of these techniques improves the efficiency of the training process.\n",
    "\n",
    "I use the categorical_crossentropy loss function because this a good loss function for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs,outputs=outpus)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit_generator(train_generator, train_steps_per_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
